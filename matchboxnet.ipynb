{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the notebook where I will augment my data extract my Features,and decide what architecture to use and train my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import warnings\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import librosa\n",
    "from torchaudio.functional import preemphasis\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\CNN Project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>chapter</th>\n",
       "      <th>reciter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abd_albassit_abd_samad_1_rir.wav</td>\n",
       "      <td>surah_al_dhoha</td>\n",
       "      <td>abd_albassit_abd_samad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abd_albassit_abd_samad_1_org.wav</td>\n",
       "      <td>surah_al_dhoha</td>\n",
       "      <td>abd_albassit_abd_samad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abd_albassit_abd_samad_2_bg.wav</td>\n",
       "      <td>surah_al_dhoha</td>\n",
       "      <td>abd_albassit_abd_samad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abd_albassit_abd_samad_2_org.wav</td>\n",
       "      <td>surah_al_dhoha</td>\n",
       "      <td>abd_albassit_abd_samad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abd_albassit_abd_samad_3_bg.wav</td>\n",
       "      <td>surah_al_dhoha</td>\n",
       "      <td>abd_albassit_abd_samad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               path         chapter                 reciter\n",
       "0  abd_albassit_abd_samad_1_rir.wav  surah_al_dhoha  abd_albassit_abd_samad\n",
       "1  abd_albassit_abd_samad_1_org.wav  surah_al_dhoha  abd_albassit_abd_samad\n",
       "2   abd_albassit_abd_samad_2_bg.wav  surah_al_dhoha  abd_albassit_abd_samad\n",
       "3  abd_albassit_abd_samad_2_org.wav  surah_al_dhoha  abd_albassit_abd_samad\n",
       "4   abd_albassit_abd_samad_3_bg.wav  surah_al_dhoha  abd_albassit_abd_samad"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"dataset2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my possible options:-Noise Injection/-Reverberation /- Background Noise Simulation/-Volume Perturbation/-Clipping/-Equalization (EQ) Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Loading Data Done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedAudioDataset(Dataset):\n",
    "    def __init__(self, csv_file, audio_dir, transform=None, max_length=22050*5,is_test=False):#max length change \n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.audio_dir = audio_dir\n",
    "        self.transform = transform\n",
    "        self.max_length = max_length\n",
    "        if not is_test:\n",
    "            self.label_encoder = LabelEncoder()\n",
    "            self.data['reciter'] = self.label_encoder.fit_transform(self.data['reciter'])\n",
    "        self.is_test = is_test\n",
    "\n",
    "        # Pre-load all audio files\n",
    "        self.audio_data = self.preload_audio(self.max_length)\n",
    "\n",
    "    def preload_audio(self,max_length):\n",
    "        audio_data = {}\n",
    "        for _, row in tqdm(self.data.iterrows(), total=len(self.data), desc=\"Preloading audio\"):\n",
    "            audio_path = os.path.join(self.audio_dir, row['path'])\n",
    "            waveform, sample_rate = torchaudio.load(audio_path)\n",
    "            if sample_rate != 22050:\n",
    "                # Resample the audio\n",
    "                resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=22050)\n",
    "                waveform = resampler(waveform)\n",
    "            if waveform.shape[0] > 1:\n",
    "                waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "            # if waveform.shape[1] < self.max_length:\n",
    "            #     padding = torch.zeros(1, self.max_length - waveform.shape[1])\n",
    "            #     waveform = torch.cat([waveform, padding], dim=1)\n",
    "            # else:\n",
    "            #     waveform = waveform[:, :self.max_length]\n",
    "            if waveform.shape[-1] < max_length:\n",
    "                padding = torch.zeros(max_length - waveform.shape[-1])\n",
    "                padded_audio = torch.cat((waveform, padding), dim=-1)\n",
    "                audio_data[row['path']] = padded_audio\n",
    "            elif waveform.shape[-1] > max_length:\n",
    "                truncated_audio = waveform[:, :max_length]\n",
    "                audio_data[row['path']] = truncated_audio\n",
    "            else:\n",
    "                audio_data[row['path']] = waveform\n",
    "        return audio_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        audio_filepath = self.data.iloc[idx]['path']\n",
    "        waveform = self.audio_data[audio_filepath]\n",
    "\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "\n",
    "        \n",
    "        if self.is_test:\n",
    "            return waveform\n",
    "        else:\n",
    "            label = self.data.iloc[idx]['reciter']\n",
    "            return waveform, label\n",
    "       \n",
    "\n",
    "def optimized_audio_transform(waveform, sample_rate=22050, n_mels=128, n_fft=400, hop_length=120):\n",
    "    # Apply pre-emphasis filter\n",
    "    waveform = torchaudio.functional.preemphasis(waveform)\n",
    "\n",
    "    # Compute mel spectrogram\n",
    "    lfcc = torchaudio.transforms.LFCC(\n",
    "    sample_rate=sample_rate,\n",
    "    n_filter=n_mels,\n",
    "    n_lfcc=64,                      # Number of LFCC coefficients to extract\n",
    "    speckwargs={\"n_fft\": 400, \"hop_length\": 120, \"center\": False},         # Additional arguments for spectrogram computation\n",
    ")(waveform)\n",
    "\n",
    "\n",
    "    return lfcc.squeeze(0).transpose(0, 1)  # Reshape to (time_steps, n_lfcc)\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    if isinstance(batch[0], tuple):\n",
    "        waveforms, labels = zip(*batch)\n",
    "        waveforms = torch.stack(waveforms)\n",
    "        return waveforms, torch.tensor(labels)\n",
    "    else:\n",
    "        return torch.stack(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preloading audio: 100%|██████████| 6650/6650 [00:19<00:00, 348.64it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_dataset = OptimizedAudioDataset(csv_file=\"dataset2.csv\",\n",
    "                                      audio_dir=\"Dataset\",\n",
    "                                      transform=optimized_audio_transform)\n",
    "\n",
    "train_data, val_data = train_test_split(train_dataset, test_size=0.1, random_state=42,\n",
    "                                        stratify=train_dataset.data['reciter'])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True,\n",
    "                          collate_fn=custom_collate_fn, num_workers=0)\n",
    "\n",
    "val_loader = DataLoader(val_data, batch_size=100, shuffle=False,\n",
    "                        collate_fn=custom_collate_fn, num_workers=0)\n",
    "\n",
    "# test_dataset = OptimizedAudioDataset(csv_file=\"/content/Test_1 (1).csv\",\n",
    "#                                      audio_dir=\"/content/drive/MyDrive/Cleaned_TechCabal_01\",\n",
    "#                                      transform=optimized_audio_transform,\n",
    "#                                      is_test=True)\n",
    "\n",
    "# test_loader = DataLoader(test_dataset, batch_size=70, shuffle=False,\n",
    "#                          collate_fn=custom_collate_fn, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=[]\n",
    "for i in range (1000):\n",
    "    data,label=train_data[i]\n",
    "    t.append(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({690: 1000})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation block for channel-wise attention\n",
    "    \"\"\"\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class TCSConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(TCSConv, self).__init__()\n",
    "        self.depthwise_conv = nn.Conv1d(in_channels, in_channels, kernel_size, groups=in_channels, padding='same')\n",
    "        self.pointwise_conv = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        self.se = SEBlock(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.pointwise_conv(x)\n",
    "        x = self.se(x)\n",
    "        return x\n",
    "\n",
    "class SubBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(SubBlock, self).__init__()\n",
    "        self.tcs_conv = TCSConv(in_channels, out_channels, kernel_size)\n",
    "        self.bnorm = nn.BatchNorm1d(out_channels)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = x\n",
    "        x = self.tcs_conv(x)\n",
    "        x = self.bnorm(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        # Add residual connection if input and output channels match\n",
    "        if x.shape == residual.shape:\n",
    "            x += residual\n",
    "        return x\n",
    "\n",
    "class MainBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, R=1):\n",
    "        super(MainBlock, self).__init__()\n",
    "        self.residual_pointwise = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        self.residual_batchnorm = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.sub_blocks = nn.ModuleList([\n",
    "            SubBlock(in_channels if i == 0 else out_channels, out_channels, kernel_size)\n",
    "            for i in range(R)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.residual_batchnorm(self.residual_pointwise(x))\n",
    "        for layer in self.sub_blocks:\n",
    "            x = layer(x)\n",
    "        return x + residual  # Add the residual connection at the end of the MainBlock\n",
    "\n",
    "class MatchboxNet(nn.Module):\n",
    "    def __init__(self, B, R, C, kernel_sizes=None, NUM_CLASSES=30):\n",
    "        super(MatchboxNet, self).__init__()\n",
    "        if not kernel_sizes:\n",
    "            kernel_sizes = [k*2+11 for k in range(1, B+1)]\n",
    "\n",
    "        self.prologue = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=11, stride=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            MainBlock(128 if i == 0 else C, C, kernel_size=kernel_sizes[i], R=R)\n",
    "            for i in range(B)\n",
    "        ])\n",
    "\n",
    "        self.epilogue = nn.Sequential(\n",
    "            nn.Conv1d(C, 128, kernel_size=29, dilation=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 128, kernel_size=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 128, kernel_size=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, NUM_CLASSES, kernel_size=1),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prologue(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.epilogue(x).squeeze(2)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 128, 368]          90,240\n",
      "       BatchNorm1d-2             [-1, 128, 368]             256\n",
      "              ReLU-3             [-1, 128, 368]               0\n",
      "            Conv1d-4              [-1, 64, 368]           8,256\n",
      "       BatchNorm1d-5              [-1, 64, 368]             128\n",
      "            Conv1d-6             [-1, 128, 368]           1,792\n",
      "            Conv1d-7              [-1, 64, 368]           8,256\n",
      " AdaptiveAvgPool1d-8                [-1, 64, 1]               0\n",
      "            Linear-9                    [-1, 4]             256\n",
      "             ReLU-10                    [-1, 4]               0\n",
      "           Linear-11                   [-1, 64]             256\n",
      "          Sigmoid-12                   [-1, 64]               0\n",
      "          SEBlock-13              [-1, 64, 368]               0\n",
      "          TCSConv-14              [-1, 64, 368]               0\n",
      "      BatchNorm1d-15              [-1, 64, 368]             128\n",
      "             ReLU-16              [-1, 64, 368]               0\n",
      "          Dropout-17              [-1, 64, 368]               0\n",
      "         SubBlock-18              [-1, 64, 368]               0\n",
      "           Conv1d-19              [-1, 64, 368]             896\n",
      "           Conv1d-20              [-1, 64, 368]           4,160\n",
      "AdaptiveAvgPool1d-21                [-1, 64, 1]               0\n",
      "           Linear-22                    [-1, 4]             256\n",
      "             ReLU-23                    [-1, 4]               0\n",
      "           Linear-24                   [-1, 64]             256\n",
      "          Sigmoid-25                   [-1, 64]               0\n",
      "          SEBlock-26              [-1, 64, 368]               0\n",
      "          TCSConv-27              [-1, 64, 368]               0\n",
      "      BatchNorm1d-28              [-1, 64, 368]             128\n",
      "             ReLU-29              [-1, 64, 368]               0\n",
      "          Dropout-30              [-1, 64, 368]               0\n",
      "         SubBlock-31              [-1, 64, 368]               0\n",
      "        MainBlock-32              [-1, 64, 368]               0\n",
      "           Conv1d-33              [-1, 64, 368]           4,160\n",
      "      BatchNorm1d-34              [-1, 64, 368]             128\n",
      "           Conv1d-35              [-1, 64, 368]           1,024\n",
      "           Conv1d-36              [-1, 64, 368]           4,160\n",
      "AdaptiveAvgPool1d-37                [-1, 64, 1]               0\n",
      "           Linear-38                    [-1, 4]             256\n",
      "             ReLU-39                    [-1, 4]               0\n",
      "           Linear-40                   [-1, 64]             256\n",
      "          Sigmoid-41                   [-1, 64]               0\n",
      "          SEBlock-42              [-1, 64, 368]               0\n",
      "          TCSConv-43              [-1, 64, 368]               0\n",
      "      BatchNorm1d-44              [-1, 64, 368]             128\n",
      "             ReLU-45              [-1, 64, 368]               0\n",
      "          Dropout-46              [-1, 64, 368]               0\n",
      "         SubBlock-47              [-1, 64, 368]               0\n",
      "           Conv1d-48              [-1, 64, 368]           1,024\n",
      "           Conv1d-49              [-1, 64, 368]           4,160\n",
      "AdaptiveAvgPool1d-50                [-1, 64, 1]               0\n",
      "           Linear-51                    [-1, 4]             256\n",
      "             ReLU-52                    [-1, 4]               0\n",
      "           Linear-53                   [-1, 64]             256\n",
      "          Sigmoid-54                   [-1, 64]               0\n",
      "          SEBlock-55              [-1, 64, 368]               0\n",
      "          TCSConv-56              [-1, 64, 368]               0\n",
      "      BatchNorm1d-57              [-1, 64, 368]             128\n",
      "             ReLU-58              [-1, 64, 368]               0\n",
      "          Dropout-59              [-1, 64, 368]               0\n",
      "         SubBlock-60              [-1, 64, 368]               0\n",
      "        MainBlock-61              [-1, 64, 368]               0\n",
      "           Conv1d-62              [-1, 64, 368]           4,160\n",
      "      BatchNorm1d-63              [-1, 64, 368]             128\n",
      "           Conv1d-64              [-1, 64, 368]           1,152\n",
      "           Conv1d-65              [-1, 64, 368]           4,160\n",
      "AdaptiveAvgPool1d-66                [-1, 64, 1]               0\n",
      "           Linear-67                    [-1, 4]             256\n",
      "             ReLU-68                    [-1, 4]               0\n",
      "           Linear-69                   [-1, 64]             256\n",
      "          Sigmoid-70                   [-1, 64]               0\n",
      "          SEBlock-71              [-1, 64, 368]               0\n",
      "          TCSConv-72              [-1, 64, 368]               0\n",
      "      BatchNorm1d-73              [-1, 64, 368]             128\n",
      "             ReLU-74              [-1, 64, 368]               0\n",
      "          Dropout-75              [-1, 64, 368]               0\n",
      "         SubBlock-76              [-1, 64, 368]               0\n",
      "           Conv1d-77              [-1, 64, 368]           1,152\n",
      "           Conv1d-78              [-1, 64, 368]           4,160\n",
      "AdaptiveAvgPool1d-79                [-1, 64, 1]               0\n",
      "           Linear-80                    [-1, 4]             256\n",
      "             ReLU-81                    [-1, 4]               0\n",
      "           Linear-82                   [-1, 64]             256\n",
      "          Sigmoid-83                   [-1, 64]               0\n",
      "          SEBlock-84              [-1, 64, 368]               0\n",
      "          TCSConv-85              [-1, 64, 368]               0\n",
      "      BatchNorm1d-86              [-1, 64, 368]             128\n",
      "             ReLU-87              [-1, 64, 368]               0\n",
      "          Dropout-88              [-1, 64, 368]               0\n",
      "         SubBlock-89              [-1, 64, 368]               0\n",
      "        MainBlock-90              [-1, 64, 368]               0\n",
      "           Conv1d-91             [-1, 128, 312]         237,696\n",
      "      BatchNorm1d-92             [-1, 128, 312]             256\n",
      "             ReLU-93             [-1, 128, 312]               0\n",
      "           Conv1d-94             [-1, 128, 312]          16,512\n",
      "      BatchNorm1d-95             [-1, 128, 312]             256\n",
      "             ReLU-96             [-1, 128, 312]               0\n",
      "           Conv1d-97             [-1, 128, 312]          16,512\n",
      "      BatchNorm1d-98             [-1, 128, 312]             256\n",
      "             ReLU-99             [-1, 128, 312]               0\n",
      "          Conv1d-100              [-1, 17, 312]           2,193\n",
      "AdaptiveAvgPool1d-101                [-1, 17, 1]               0\n",
      "================================================================\n",
      "Total params: 421,073\n",
      "Trainable params: 421,073\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.18\n",
      "Forward/backward pass size (MB): 14.29\n",
      "Params size (MB): 1.61\n",
      "Estimated Total Size (MB): 16.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = MatchboxNet(B=3, R=2, C=64, NUM_CLASSES=17)\n",
    "summary(model, input_size=(64, 746))  # Adjust input_size to     match (batch_size, input_dim),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using.. cpu\n",
      "Epoch [1/100] Train Loss: 1.0784, Train Acc: 0.7890 Val Loss: 0.5340, Val Acc: 0.8647\n",
      "--------------------\n",
      "Epoch [2/100] Train Loss: 0.2692, Train Acc: 0.9519 Val Loss: 0.3510, Val Acc: 0.8977\n",
      "--------------------\n",
      "Epoch [3/100] Train Loss: 0.1735, Train Acc: 0.9586 Val Loss: 0.1670, Val Acc: 0.9639\n",
      "--------------------\n",
      "Epoch [4/100] Train Loss: 0.1270, Train Acc: 0.9673 Val Loss: 0.9925, Val Acc: 0.7940\n",
      "--------------------\n",
      "Epoch [5/100] Train Loss: 0.1163, Train Acc: 0.9669 Val Loss: 0.2569, Val Acc: 0.9263\n",
      "--------------------\n",
      "Epoch [6/100] Train Loss: 0.1067, Train Acc: 0.9711 Val Loss: 0.1921, Val Acc: 0.9429\n",
      "--------------------\n",
      "Epoch [7/100] Train Loss: 0.0865, Train Acc: 0.9744 Val Loss: 0.1967, Val Acc: 0.9414\n",
      "--------------------\n",
      "Epoch [8/100] Train Loss: 0.0868, Train Acc: 0.9758 Val Loss: 0.3336, Val Acc: 0.9188\n",
      "--------------------\n",
      "Epoch [9/100] Train Loss: 0.0687, Train Acc: 0.9803 Val Loss: 0.1445, Val Acc: 0.9549\n",
      "--------------------\n",
      "Epoch [10/100] Train Loss: 0.0719, Train Acc: 0.9786 Val Loss: 0.1100, Val Acc: 0.9624\n",
      "--------------------\n",
      "Epoch [11/100] Train Loss: 0.0610, Train Acc: 0.9830 Val Loss: 0.1716, Val Acc: 0.9489\n",
      "--------------------\n",
      "Epoch [12/100] Train Loss: 0.0840, Train Acc: 0.9733 Val Loss: 0.1825, Val Acc: 0.9534\n",
      "--------------------\n",
      "Epoch [13/100] Train Loss: 0.0477, Train Acc: 0.9865 Val Loss: 0.3080, Val Acc: 0.9383\n",
      "--------------------\n",
      "Epoch [14/100] Train Loss: 0.0503, Train Acc: 0.9851 Val Loss: 0.1252, Val Acc: 0.9639\n",
      "--------------------\n",
      "Epoch [15/100] Train Loss: 0.0472, Train Acc: 0.9851 Val Loss: 0.1504, Val Acc: 0.9579\n",
      "--------------------\n",
      "Epoch [16/100] Train Loss: 0.0505, Train Acc: 0.9855 Val Loss: 0.1693, Val Acc: 0.9594\n",
      "--------------------\n",
      "Epoch [17/100] Train Loss: 0.0251, Train Acc: 0.9921 Val Loss: 0.0787, Val Acc: 0.9669\n",
      "--------------------\n",
      "Epoch [18/100] Train Loss: 0.0145, Train Acc: 0.9955 Val Loss: 0.0478, Val Acc: 0.9850\n",
      "--------------------\n",
      "Epoch [19/100] Train Loss: 0.0132, Train Acc: 0.9965 Val Loss: 0.0372, Val Acc: 0.9880\n",
      "--------------------\n",
      "Epoch [20/100] Train Loss: 0.0124, Train Acc: 0.9960 Val Loss: 0.0594, Val Acc: 0.9805\n",
      "--------------------\n",
      "Epoch [21/100] Train Loss: 0.0162, Train Acc: 0.9948 Val Loss: 0.0439, Val Acc: 0.9880\n",
      "--------------------\n",
      "Epoch [22/100] Train Loss: 0.0109, Train Acc: 0.9968 Val Loss: 0.0597, Val Acc: 0.9835\n",
      "--------------------\n",
      "Epoch [23/100] Train Loss: 0.0091, Train Acc: 0.9972 Val Loss: 0.0457, Val Acc: 0.9880\n",
      "--------------------\n",
      "Epoch [24/100] Train Loss: 0.0101, Train Acc: 0.9973 Val Loss: 0.0409, Val Acc: 0.9805\n",
      "--------------------\n",
      "Epoch [25/100] Train Loss: 0.0085, Train Acc: 0.9977 Val Loss: 0.0706, Val Acc: 0.9805\n",
      "--------------------\n",
      "Epoch [26/100] Train Loss: 0.0056, Train Acc: 0.9988 Val Loss: 0.0382, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [27/100] Train Loss: 0.0032, Train Acc: 0.9997 Val Loss: 0.0306, Val Acc: 0.9880\n",
      "--------------------\n",
      "Epoch [28/100] Train Loss: 0.0029, Train Acc: 0.9997 Val Loss: 0.0284, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [29/100] Train Loss: 0.0035, Train Acc: 0.9992 Val Loss: 0.0297, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [30/100] Train Loss: 0.0058, Train Acc: 0.9987 Val Loss: 0.0281, Val Acc: 0.9880\n",
      "--------------------\n",
      "Epoch [31/100] Train Loss: 0.0037, Train Acc: 0.9992 Val Loss: 0.0269, Val Acc: 0.9925\n",
      "--------------------\n",
      "Epoch [32/100] Train Loss: 0.0028, Train Acc: 0.9995 Val Loss: 0.0426, Val Acc: 0.9880\n",
      "--------------------\n",
      "Epoch [33/100] Train Loss: 0.0036, Train Acc: 0.9995 Val Loss: 0.0304, Val Acc: 0.9865\n",
      "--------------------\n",
      "Epoch [34/100] Train Loss: 0.0029, Train Acc: 0.9992 Val Loss: 0.0256, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [35/100] Train Loss: 0.0030, Train Acc: 0.9990 Val Loss: 0.0432, Val Acc: 0.9835\n",
      "--------------------\n",
      "Epoch [36/100] Train Loss: 0.0039, Train Acc: 0.9987 Val Loss: 0.0683, Val Acc: 0.9805\n",
      "--------------------\n",
      "Epoch [37/100] Train Loss: 0.0038, Train Acc: 0.9992 Val Loss: 0.0249, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [38/100] Train Loss: 0.0017, Train Acc: 0.9998 Val Loss: 0.0326, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [39/100] Train Loss: 0.0023, Train Acc: 0.9997 Val Loss: 0.0293, Val Acc: 0.9850\n",
      "--------------------\n",
      "Epoch [40/100] Train Loss: 0.0038, Train Acc: 0.9990 Val Loss: 0.0796, Val Acc: 0.9805\n",
      "--------------------\n",
      "Epoch [41/100] Train Loss: 0.0038, Train Acc: 0.9990 Val Loss: 0.0383, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [42/100] Train Loss: 0.0037, Train Acc: 0.9988 Val Loss: 0.0364, Val Acc: 0.9850\n",
      "--------------------\n",
      "Epoch [43/100] Train Loss: 0.0030, Train Acc: 0.9990 Val Loss: 0.0395, Val Acc: 0.9850\n",
      "--------------------\n",
      "Epoch [44/100] Train Loss: 0.0020, Train Acc: 1.0000 Val Loss: 0.0299, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [45/100] Train Loss: 0.0016, Train Acc: 0.9997 Val Loss: 0.0296, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [46/100] Train Loss: 0.0010, Train Acc: 1.0000 Val Loss: 0.0241, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [47/100] Train Loss: 0.0024, Train Acc: 0.9993 Val Loss: 0.0202, Val Acc: 0.9940\n",
      "--------------------\n",
      "Epoch [48/100] Train Loss: 0.0020, Train Acc: 0.9997 Val Loss: 0.0296, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [49/100] Train Loss: 0.0010, Train Acc: 1.0000 Val Loss: 0.0219, Val Acc: 0.9940\n",
      "--------------------\n",
      "Epoch [50/100] Train Loss: 0.0012, Train Acc: 1.0000 Val Loss: 0.0241, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [51/100] Train Loss: 0.0008, Train Acc: 1.0000 Val Loss: 0.0194, Val Acc: 0.9940\n",
      "--------------------\n",
      "Epoch [52/100] Train Loss: 0.0008, Train Acc: 1.0000 Val Loss: 0.0295, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [53/100] Train Loss: 0.0008, Train Acc: 0.9998 Val Loss: 0.0195, Val Acc: 0.9940\n",
      "--------------------\n",
      "Epoch [54/100] Train Loss: 0.0008, Train Acc: 0.9998 Val Loss: 0.0230, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [55/100] Train Loss: 0.0022, Train Acc: 0.9992 Val Loss: 0.0301, Val Acc: 0.9925\n",
      "--------------------\n",
      "Epoch [56/100] Train Loss: 0.0013, Train Acc: 0.9998 Val Loss: 0.0231, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [57/100] Train Loss: 0.0006, Train Acc: 1.0000 Val Loss: 0.0194, Val Acc: 0.9925\n",
      "--------------------\n",
      "Epoch [58/100] Train Loss: 0.0017, Train Acc: 0.9997 Val Loss: 0.0289, Val Acc: 0.9880\n",
      "--------------------\n",
      "Epoch [59/100] Train Loss: 0.0019, Train Acc: 0.9997 Val Loss: 0.0280, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [60/100] Train Loss: 0.0007, Train Acc: 1.0000 Val Loss: 0.0259, Val Acc: 0.9865\n",
      "--------------------\n",
      "Epoch [61/100] Train Loss: 0.0007, Train Acc: 1.0000 Val Loss: 0.0200, Val Acc: 0.9925\n",
      "--------------------\n",
      "Epoch [62/100] Train Loss: 0.0007, Train Acc: 1.0000 Val Loss: 0.0188, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [63/100] Train Loss: 0.0005, Train Acc: 1.0000 Val Loss: 0.0230, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [64/100] Train Loss: 0.0007, Train Acc: 1.0000 Val Loss: 0.0319, Val Acc: 0.9880\n",
      "--------------------\n",
      "Epoch [65/100] Train Loss: 0.0015, Train Acc: 0.9995 Val Loss: 0.0360, Val Acc: 0.9880\n",
      "--------------------\n",
      "Epoch [66/100] Train Loss: 0.0016, Train Acc: 0.9993 Val Loss: 0.0311, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [67/100] Train Loss: 0.0016, Train Acc: 0.9995 Val Loss: 0.0237, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [68/100] Train Loss: 0.0012, Train Acc: 0.9997 Val Loss: 0.0434, Val Acc: 0.9850\n",
      "--------------------\n",
      "Epoch [69/100] Train Loss: 0.0008, Train Acc: 1.0000 Val Loss: 0.0203, Val Acc: 0.9925\n",
      "--------------------\n",
      "Epoch [70/100] Train Loss: 0.0007, Train Acc: 1.0000 Val Loss: 0.0256, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [71/100] Train Loss: 0.0006, Train Acc: 1.0000 Val Loss: 0.0251, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [72/100] Train Loss: 0.0007, Train Acc: 0.9998 Val Loss: 0.0235, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [73/100] Train Loss: 0.0005, Train Acc: 1.0000 Val Loss: 0.0246, Val Acc: 0.9880\n",
      "--------------------\n",
      "Epoch [74/100] Train Loss: 0.0006, Train Acc: 1.0000 Val Loss: 0.0244, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [75/100] Train Loss: 0.0007, Train Acc: 0.9998 Val Loss: 0.0226, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [76/100] Train Loss: 0.0005, Train Acc: 1.0000 Val Loss: 0.0230, Val Acc: 0.9925\n",
      "--------------------\n",
      "Epoch [77/100] Train Loss: 0.0005, Train Acc: 1.0000 Val Loss: 0.0210, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [78/100] Train Loss: 0.0004, Train Acc: 1.0000 Val Loss: 0.0224, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [79/100] Train Loss: 0.0013, Train Acc: 0.9998 Val Loss: 0.0199, Val Acc: 0.9925\n",
      "--------------------\n",
      "Epoch [80/100] Train Loss: 0.0006, Train Acc: 1.0000 Val Loss: 0.0250, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [81/100] Train Loss: 0.0006, Train Acc: 1.0000 Val Loss: 0.0209, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [82/100] Train Loss: 0.0005, Train Acc: 1.0000 Val Loss: 0.0206, Val Acc: 0.9940\n",
      "--------------------\n",
      "Epoch [83/100] Train Loss: 0.0007, Train Acc: 0.9998 Val Loss: 0.0196, Val Acc: 0.9925\n",
      "--------------------\n",
      "Epoch [84/100] Train Loss: 0.0011, Train Acc: 0.9997 Val Loss: 0.0186, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [85/100] Train Loss: 0.0003, Train Acc: 1.0000 Val Loss: 0.0226, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [86/100] Train Loss: 0.0004, Train Acc: 1.0000 Val Loss: 0.0200, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [87/100] Train Loss: 0.0004, Train Acc: 1.0000 Val Loss: 0.0218, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [88/100] Train Loss: 0.0005, Train Acc: 1.0000 Val Loss: 0.0214, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [89/100] Train Loss: 0.0008, Train Acc: 1.0000 Val Loss: 0.0234, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [90/100] Train Loss: 0.0004, Train Acc: 1.0000 Val Loss: 0.0236, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [91/100] Train Loss: 0.0003, Train Acc: 1.0000 Val Loss: 0.0213, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [92/100] Train Loss: 0.0004, Train Acc: 1.0000 Val Loss: 0.0213, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [93/100] Train Loss: 0.0005, Train Acc: 1.0000 Val Loss: 0.0225, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [94/100] Train Loss: 0.0004, Train Acc: 1.0000 Val Loss: 0.0219, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [95/100] Train Loss: 0.0011, Train Acc: 0.9998 Val Loss: 0.0207, Val Acc: 0.9925\n",
      "--------------------\n",
      "Epoch [96/100] Train Loss: 0.0004, Train Acc: 1.0000 Val Loss: 0.0211, Val Acc: 0.9895\n",
      "--------------------\n",
      "Epoch [97/100] Train Loss: 0.0005, Train Acc: 1.0000 Val Loss: 0.0193, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [98/100] Train Loss: 0.0005, Train Acc: 1.0000 Val Loss: 0.0211, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [99/100] Train Loss: 0.0009, Train Acc: 0.9997 Val Loss: 0.0218, Val Acc: 0.9910\n",
      "--------------------\n",
      "Epoch [100/100] Train Loss: 0.0004, Train Acc: 1.0000 Val Loss: 0.0208, Val Acc: 0.9910\n",
      "--------------------\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, patience=5, grad_clip=1.0):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using..\",device)\n",
    "    model.to(device)\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=patience, verbose=True)\n",
    "   # scheduler = OneCycleLR(\n",
    "    #optimizer,\n",
    "  #  max_lr=0.01,  # Maximum learning rate\n",
    "   # steps_per_epoch=steps_per_epoch,\n",
    "  #  epochs=num_epochs,\n",
    "   # pct_start=0.3,  # Percentage of the cycle to increase learning rate\n",
    "   # anneal_strategy='cos',  # Annealing strategy ('linear' or 'cos')\n",
    "   # div_factor=25.0,  # Initial learning rate = max_lr / div_factor\n",
    "   # final_div_factor=1e4  # Minimum learning rate = initial_lr / final_div_factor\n",
    "#)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            inputs = inputs.permute(0, 2, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                inputs = inputs.permute(0, 2, 1)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "        # Adjust learning rate based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'Matchboxnet_bestModel/MatchboxNet_best_model1.pt')\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "num_classes = len(train_dataset.label_encoder.classes_)\n",
    "model = MatchboxNet(B=3, R=2, C=64, NUM_CLASSES=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inference = MatchboxNet(B=3, R=2, C=64, NUM_CLASSES=17)\n",
    "model_inference.load_state_dict(torch.load('Matchboxnet_bestModel/MatchboxNet_best_model1.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preloading audio: 100%|██████████| 7/7 [00:00<00:00, 77.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL is using CPU for Inferencing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = OptimizedAudioDataset(csv_file=\"test.csv\",\n",
    "                                      audio_dir=\"test/Test\",\n",
    "                                      transform=optimized_audio_transform,\n",
    "                                      is_test=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=70, shuffle=False,\n",
    "                          collate_fn=custom_collate_fn, num_workers=0)\n",
    "                        \n",
    "def predict_test_data(model, test_loader):\n",
    "    device = \"cpu\"\n",
    "    model.to(device)\n",
    "    print(\"MODEL is using CPU for Inferencing....\")\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for inputs in tqdm(test_loader, desc=\"Inferencing\"):\n",
    "            inputs = inputs.to(device)\n",
    "            inputs = inputs.permute(0, 2, 1)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    return predictions\n",
    "\n",
    "test_predictions = predict_test_data(model_inference, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\CNN Project\\test\\Test\\Ahmed_ali_ajmi.wav</td>\n",
       "      <td>Ahmed_ali_ajmi.m4a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\CNN Project\\test\\Test\\Alimahmoud.wav</td>\n",
       "      <td>Alimahmoud.m4a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\CNN Project\\test\\Test\\Islem_sob7i.wav</td>\n",
       "      <td>Islem_sob7i.m4a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\CNN Project\\test\\Test\\Yaser_aldousari.wav</td>\n",
       "      <td>Yaser_aldousari.m4a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\CNN Project\\test\\Test\\Youssef_aidours.wav</td>\n",
       "      <td>Youssef_aidours.m4a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:\\CNN Project\\test\\Test\\phone_audio.wav</td>\n",
       "      <td>yasser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:\\CNN Project\\test\\Test\\surah_al_mulk-yasser_...</td>\n",
       "      <td>yasser</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path                label\n",
       "0        C:\\CNN Project\\test\\Test\\Ahmed_ali_ajmi.wav   Ahmed_ali_ajmi.m4a\n",
       "1            C:\\CNN Project\\test\\Test\\Alimahmoud.wav       Alimahmoud.m4a\n",
       "2           C:\\CNN Project\\test\\Test\\Islem_sob7i.wav      Islem_sob7i.m4a\n",
       "3       C:\\CNN Project\\test\\Test\\Yaser_aldousari.wav  Yaser_aldousari.m4a\n",
       "4       C:\\CNN Project\\test\\Test\\Youssef_aidours.wav  Youssef_aidours.m4a\n",
       "5           C:\\CNN Project\\test\\Test\\phone_audio.wav               yasser\n",
       "6  C:\\CNN Project\\test\\Test\\surah_al_mulk-yasser_...               yasser"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv(\"test.csv\")\n",
    "test.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ahmed_alijmi', 'maher_alm3i9li', 'ahmed_alijmi',\n",
       "       'abd_albassit_abd_samad', 'maher_alm3i9li', 'yasser_aldossari',\n",
       "       'yasser_aldossari'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.label_encoder.inverse_transform(test_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
